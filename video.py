# -*- coding: utf-8 -*-
"""Video

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h720-H40cNY8HC-6Vi_cGxLAMtb2vynF
"""

import numpy as np
from tqdm import tqdm
import cv2
import numpy as np

def generate_video(environment, episodes, filename, model=None):
    """
    Generate a video for a RL agent in a given environment.

    :param environment: gym environment to create video for
    :type environment: OpenAI Gym Environment
    :param episodes: number of episodes to run
    :type episodes: int
    :param filename: filename to save to
    :type filename: str
    :model: model to predict optimal action or None for random actions
    :type model: ?
    :return: None
    """
    screens = []

    for ep in range(episodes):
      environment.reset()
      for step in tqdm(range(play_args.max_ep_length)):
        screen = env.render(mode = 'rgb_array')
        screens.append(screen)
        action = environment.action_space.sample()
   
    height, width, layers = screens[0].shape

    fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')
    video = cv2.VideoWriter('gameplay.avi', fourcc, 60, (width, height))

    for screen in tqdm(screens):
      video.write(screen)

    cv2.destroyAllWindows()
    video.release()
    filename = open('gameplay.avi', 'rb')
    # reset and step through environment for given number of episodes
        # either use random actions or use the model to predict the next action
        # add new observation to screens
    # save the screens as a video to the given filename
    # bonus: convert to an mp4 file

!ffmpeg -i gameplay.avi gameplay.mp4

from IPython.display import HTML
from base64 import b64encode
mp4 = open('gameplay.mp4', 'rb').read()
data_url = "data:video/mp4;base64," + b64encode(mp4).decode()
HTML("""
<video width=400 controls>
      <source src="%s" type="video/mp4">
</video>
""" % data_url)